# =====================================================================================
# GRPO (Generalized Reinforcement Learning with Proximal Optimization) Configuration
# MODIFIED FOR CLEAN LOGS & CPU EXECUTION (EXTREME MEMORY SAVING)
# =====================================================================================

# --- Model & Tokenizer Configuration ---
# NOTE: This path should point to a Supervised Fine-Tuned (SFT) adapter, not a base model.
model_name_or_path: "./checkpoints/sft-tinyllama-guanaco-cpu/final_model"
tokenizer_path: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
use_fast_tokenizer: true

# --- Quantization Control ---
# Set to true to enable int8 dynamic quantization on the non-trainable reference model.
quantize_models: true

# --- Dataset ---
# A dummy dataset will be created if dataset_name is not specified.
# dataset_name: "imdb"
# dataset_text_field: "text"
num_prompts_for_demo: 32 # Total number of prompts in our dummy dataset if no real dataset is used.
dataset_subset_size: 4 # Use a small subset for quick testing runs.

# --- GRPO Specific Parameters ---
max_steps: 20
learning_rate: 1.41e-5
per_device_train_batch_size: 1 # Micro-batch size per GPU. MUST be 1 for memory-optimized version.
gradient_accumulation_steps: 4
num_generations: 4 # Number of completions to generate for each prompt.
num_iterations: 4 # Number of optimization iterations on the same batch (like PPO epochs).
beta: 0.1
temperature: 1.0
epsilon_low: 0.2
epsilon_high: 0.2
scale_rewards: true

# --- Reward Configuration ---
reward_funcs: [ "accuracy", "format", "tag_count" ]
reward_weights: [ 1.0, 1.0, 1.0 ]

# --- Generation Parameters for GRPO Rollouts ---
max_new_tokens: 16
min_new_tokens: 8

# --- General Training & Experiment Tracking ---
output_dir: "./checkpoints/grpo-tinyllama-guanaco-cpu-quantized"
seed: 42
log_interval: 1
run_name: "grpo-tinyllama-guanaco-demo-cpu-quantized"

# --- PEFT Configuration (LoRA for GRPO Policy Model) ---
# THIS SECTION IS CRITICAL AND WAS MISSING
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
lora_target_modules:
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"