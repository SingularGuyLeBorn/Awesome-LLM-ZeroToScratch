# FILE: configs/training/finetune_sft.yaml
# Bedrock Protocol: Configuration for Supervised Fine-Tuning (SFT) using LoRA.
# MODIFIED FOR CPU-ONLY EXECUTION & SPEED

# --- Model & Tokenizer ---
model_name_or_path: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
use_fast_tokenizer: true

# --- Dataset ---
dataset_name: "mlabonne/guanaco-llama2-1k"
dataset_text_field: "text"
# [MODIFIED FOR CPU SPEED] Add this new parameter to limit dataset size for fast CPU runs.
dataset_subset_size_cpu: 16 # Use only 16 samples for a quick run.
max_seq_length: 512

# --- PEFT / LoRA Configuration ---
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
lora_target_modules:
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"

# --- Training Arguments ---
output_dir: "./checkpoints/sft-tinyllama-guanaco-cpu"
num_train_epochs: 1
per_device_train_batch_size: 1
gradient_accumulation_steps: 4
optim: "adamw_torch"
save_steps: 10 # Save every 10 steps to have a checkpoint
logging_steps: 1 # Log every step to see progress
learning_rate: 2e-4
weight_decay: 0.001
fp16: false
bf16: false
max_grad_norm: 1.0
max_steps: 5 # [MODIFIED FOR CPU SPEED] Stop after only 5 training steps. This is the most important change.
warmup_ratio: 0.03
lr_scheduler_type: "cosine"

# --- Experiment Tracking ---
report_to: "none"
run_name: "sft-tinyllama-guanaco-demo-cpu"

# END OF FILE: configs/training/finetune_sft.yaml