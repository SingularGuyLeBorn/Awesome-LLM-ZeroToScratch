# FILE: configs/model/0.5B_dense.yaml
# Bedrock Protocol: Configuration for a 0.5 Billion (approx) Dense LLM.
# This defines the architectural hyperparameters for from-scratch pre-training.

model_type: "DenseLLM" # Custom identifier for our internal model builder

# --- Core Transformer Architecture Parameters ---
# Calculated to achieve ~0.5B parameters.
vocab_size: 32000          # Vocabulary size. Should match your tokenizer.
hidden_size: 1024          # Dimensionality of the embeddings and Transformer blocks (d_model).
intermediate_size: 4096    # Dimensionality of the feed-forward layer (d_ffn). Typically 4 * hidden_size.
num_hidden_layers: 24      # Number of Transformer blocks (L).
num_attention_heads: 16    # Number of attention heads (h). hidden_size must be divisible by num_attention_heads.
num_key_value_heads: 16    # For Multi-Head Attention (MHA), this is equal to num_attention_heads.
                             # For Grouped-Query Attention (GQA), it's a smaller number.
hidden_act: "silu"         # Activation function for the FFN (e.g., "gelu", "relu", "silu", "swiglu").
max_position_embeddings: 2048 # Maximum sequence length the model can handle.

# --- Attention Specifics ---
# Determines which attention implementation to use.
# "standard" uses PyTorch native Scaled Dot-Product Attention (SDPA) or custom.
# "flash" uses FlashAttention (if available and compatible).
attention_type: "standard" # or "flash"

# --- Tokenizer Configuration (for model loading context) ---
# This links to the tokenizer used for pre-training.
tokenizer_path: "./data/tokenizers/wikitext_spm" # Path to the trained SentencePiece tokenizer.

# --- VLM Specifics (if used with a vision encoder) ---
# For pure LLM pre-training, these are not used.
# vision_encoder_model_name_or_path: "openai/clip-vit-large-patch14"
# vision_projector_hidden_size: 2048 # MLP hidden size for mapping vision features to text embedding space.
# vision_projector_num_layers: 2     # Number of MLP layers for the vision projector.

# END OF FILE: configs/model/0.5B_dense.yaml